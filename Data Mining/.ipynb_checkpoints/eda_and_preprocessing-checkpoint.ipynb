{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "#Can be very helpful to notice any imbalance in classes\n",
    "from collections import Counter \n",
    "import sweetviz as sv\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sourced from https://www.postgresqltutorial.com/postgresql-python/connect/\n",
    "def config(filename='database.ini', section='postgresql'):\n",
    "    parser = ConfigParser()\n",
    "    # read config file\n",
    "    parser.read(filename) \n",
    " \n",
    "    # get section, default to postgresql\n",
    "    db = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            db[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n",
    " \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Section postgresql not found in the database.ini file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ccef5e8537fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Get the configuration file as a python dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-235fad5e2086>\u001b[0m in \u001b[0;36mconfig\u001b[1;34m(filename, section)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mdb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Section {0} not found in the {1} file'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Section postgresql not found in the database.ini file"
     ]
    }
   ],
   "source": [
    "#Get the configuration file as a python dictionary\n",
    "cfg = config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish the connection and create a cursor to the database\n",
    "try:\n",
    "    print(\"Here's an attempt to connect to the database\")\n",
    "    conn = psycopg2.connect(**cfg)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Look's like it was a success\")\n",
    "    \n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Lets get our data \n",
    "    cursor.execute('''SELECT p.acquisition_group, p.gender, p.age_group, s.title, f.unresolved::INTEGER, f.resolved::INTEGER,\n",
    "                    f.fatal::INTEGER, m.retail_and_recreation::INTEGER, m.grocery_and_pharmacy::INTEGER\n",
    "                    FROM covid19_tracking_fact_table f\n",
    "                    INNER JOIN onset_date_dimension d\n",
    "                    ON d.date_surrogate_key = f.onset_date_surrogate_key\n",
    "                    INNER JOIN patient_dimension p \n",
    "                    ON p.patient_surrogate_key = f.patient_surrogate_key\n",
    "                    INNER JOIN weather_dimension w \n",
    "                    ON w.weather_surrogate_key = f.weather_surrogate_key\n",
    "                    INNER JOIN special_measures_dimension s\n",
    "                    ON s.special_measures_surrogate_key = f.special_measures_surrogate_key\n",
    "                    INNER JOIN mobility_dimension m \n",
    "                    ON m.mobility_surrogate_key = f.mobility_surrogate_key\n",
    "                    '''\n",
    "                  )\n",
    "\n",
    "    #Get the complete result set. It will be a list of tuples where each tuple is a row from the result set\n",
    "    result_list = cursor.fetchall()\n",
    "        \n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure to run this cell at the end of all your experiments to close all connections\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization, Preprocessing and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, \n",
    "result_df = pd.DataFrame(result_list, columns=['acquisition_group',\n",
    "                                               'gender',\n",
    "                                               'age_group',\n",
    "                                               'special_measure',\n",
    "                                               'is_unresolved',\n",
    "                                               'is_resolved',\n",
    "                                               'is_fatal',\n",
    "                                               'retail_and_recreation_mobility',\n",
    "                                               'grocery_and_pharmacy_mobility'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_report = sv.analyze(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_report.show_notebook(  w=None, \n",
    "                h=None, \n",
    "                scale=None,\n",
    "                layout='widescreen',\n",
    "                filepath=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.drop(result_df[result_df['acquisition_group']=='MISSING INFORMATION'].index, inplace = True)\n",
    "result_df.drop(result_df[ result_df['age_group']=='UNKNOWN'].index, inplace = True)\n",
    "result_df.drop(result_df[ result_df['gender'].isin(['UNSPECIFIED', 'GENDER DIVERSE'])].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.is_unresolved.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.is_unresolved.value_counts())\n",
    "print(result_df.is_resolved.value_counts())\n",
    "print(result_df.is_fatal.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both labels are highly imbalanced! We need to make sure to consider this when we test our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result = pd.get_dummies(df, columns=['acquisition_group', 'age_group','gender','special_measure'])\n",
    "#new_result = pd.get_dummies(df, columns=['age_group','gender','special_measure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_result.iloc[:,0:3]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_result.drop(y, axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.34, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.to_csv('X_train.csv', index=False)\n",
    "# X_test.to_csv('X_test.csv', index=False)\n",
    "# y_train.to_csv('y_train.csv', index=False)\n",
    "# y_test.to_csv('y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_1d = pd.DataFrame((y_train.iloc[:, 0:] == 1).idxmax(1), columns = ['Outcome'])\n",
    "# y_test_1d = pd.DataFrame((y_test.iloc[:, 0:] == 1).idxmax(1), columns = ['Outcome'])\n",
    "# y_train_1d.to_csv('y_train_1d.csv', index=False)\n",
    "# y_test_1d.to_csv('y_test_1d.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy')\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_test)\n",
    "recall = recall_score(y_pred, y_test, average='micro') * 100\n",
    "precision = precision_score(y_pred, y_test, average='micro') * 100\n",
    "print(\"Recall of Decision Tree {:.2f} %\".format(recall))\n",
    "print(\"Precision of Decision Tree {:.2f} %\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "print(export_text(decision_tree = dt, feature_names = list(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_data = tree.export_graphviz(dt, out_file=\"mytree.dot\",  \n",
    "#                      feature_names=X_train.columns,  \n",
    "#                      class_names=y_train.columns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz\n",
    "# graph = graphviz.Source(dot_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(y_pred, columns=['is_unresolved', 'is_resolved', 'is_fatal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp.is_unresolved == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[y_test.is_fatal==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = new_result[new_result.is_unresolved==1].copy()\n",
    "new_pred.drop(y, axis = 1, inplace = True)\n",
    "new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_pred = dt.predict(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_1d = pd.read_csv('y_train_1d.csv')\n",
    "y_test_1d = pd.read_csv('y_test_1d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train_1d.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_1d.Outcome.value_counts())\n",
    "print(y_test_1d.Outcome.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gb.predict(X_test)\n",
    "recall = recall_score(y_pred, y_test_1d, average = 'micro') * 100\n",
    "precision = precision_score(y_pred, y_test_1d, average = 'micro') * 100\n",
    "print(\"Recall of Decision Tree {:.2f} %\".format(recall))\n",
    "print(\"Precision of Decision Tree {:.2f} %\".format(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "recall = recall_score(y_pred, y_test, average='micro') * 100\n",
    "precision = precision_score(y_pred, y_test, average='micro') * 100\n",
    "print(\"Recall of Decision Tree {:.2f} %\".format(recall))\n",
    "print(\"Precision of Decision Tree {:.2f} %\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
